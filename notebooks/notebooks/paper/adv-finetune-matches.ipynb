{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizes results of matches between finetuned adversaries and KataGo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "from sgf_parser import game_info\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "plt.style.use(\n",
    "    [\"tableau-colorblind10\", utils.get_style(\"default\"), utils.get_style(\"1-col\")]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b60-s7701m-v1600         1400\n",
       "230520-s97528320-v600    1200\n",
       "cp505-v1600              1000\n",
       "230518-s34275840-v600     500\n",
       "230520-s22809344-v600     500\n",
       "230520-s75567360-v600     500\n",
       "b60-s7701m-v4096          400\n",
       "cyclic-adv-v600           400\n",
       "b18-s5832m-v1600          300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.parse_sgfs(\n",
    "    [\n",
    "        \"/nas/ucb/k8/go-attack/match/ttseng-eval-ft-vs-b60-20230524-160144\",\n",
    "        \"/nas/ucb/k8/go-attack/match/ttseng-eval-ft-vs-b60-v1124-20230524-161516\",\n",
    "        \"/nas/ucb/k8/go-attack/match/ttseng-eval-ft-vs-b60-20230526-140744/\",\n",
    "        \"/nas/ucb/k8/go-attack/match/ttseng-eval-ft-vs-b60-v4096-20230526-140926\",\n",
    "        \"/nas/ucb/k8/go-attack/match/ttseng-eval-b60ft-vs-cp505-20230526-152339\",\n",
    "        \"/nas/ucb/k8/go-attack/match/ttseng-cyclic-vs-b60-s7702m-20230526-152118\",\n",
    "    ],\n",
    "    no_victim_okay=True,\n",
    ")\n",
    "pd.concat([df.b_name, df.w_name]).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversary: cyclic-adv-v600\n",
      "cyclic-adv-v600 vs b60-s7701m-v1600: 0/400 (0.00%)\n",
      "\n",
      "Adversary: 230518-s34275840-v600\n",
      "230518-s34275840-v600 vs b18-s5832m-v1600: 20/100 (20.00%)\n",
      "230518-s34275840-v600 vs b60-s7701m-v1600: 59/200 (29.50%)\n",
      "230518-s34275840-v600 vs cp505-v1600: 130/200 (65.00%)\n",
      "\n",
      "Adversary: 230520-s22809344-v600\n",
      "230520-s22809344-v600 vs b18-s5832m-v1600: 13/100 (13.00%)\n",
      "230520-s22809344-v600 vs b60-s7701m-v1600: 68/200 (34.00%)\n",
      "230520-s22809344-v600 vs cp505-v1600: 107/200 (53.50%)\n",
      "\n",
      "Adversary: 230520-s75567360-v600\n",
      "230520-s75567360-v600 vs b18-s5832m-v1600: 15/100 (15.00%)\n",
      "230520-s75567360-v600 vs b60-s7701m-v1600: 71/200 (35.50%)\n",
      "230520-s75567360-v600 vs cp505-v1600: 102/200 (51.00%)\n",
      "\n",
      "Adversary: 230520-s97528320-v600\n",
      "230520-s97528320-v600 vs b60-s7701m-v1600: 187/400 (46.75%)\n",
      "230520-s97528320-v600 vs b60-s7701m-v4096: 131/400 (32.75%)\n",
      "230520-s97528320-v600 vs cp505-v1600: 268/400 (67.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for adv in [\n",
    "    \"cyclic-adv-v600\",\n",
    "    \"230518-s34275840-v600\",\n",
    "    \"230520-s22809344-v600\",\n",
    "    \"230520-s75567360-v600\",\n",
    "    \"230520-s97528320-v600\",\n",
    "]:\n",
    "    sub_df = df.query(\"b_name == @adv or w_name == @adv\")\n",
    "\n",
    "    print(f\"Adversary: {adv}\")\n",
    "    for opp in sorted(pd.concat([sub_df.b_name, sub_df.w_name]).unique()):\n",
    "        if opp == adv:\n",
    "            continue\n",
    "\n",
    "        opp_df = sub_df.query(\n",
    "            \"|\".join(\n",
    "                [\n",
    "                    f\"(b_name == @opp and w_name == @adv)\",\n",
    "                    f\"(b_name == @adv and w_name == @opp)\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        tot_games = len(opp_df)\n",
    "        if tot_games == 0:\n",
    "            continue\n",
    "\n",
    "        n_games_won = (opp_df.win_name == adv).sum()\n",
    "        print(\n",
    "            f\"{adv} vs {opp}: {n_games_won}/{tot_games} ({n_games_won/tot_games:.2%})\"\n",
    "        )\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
