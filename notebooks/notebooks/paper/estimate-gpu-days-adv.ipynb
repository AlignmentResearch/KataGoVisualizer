{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee91fef9",
   "metadata": {},
   "source": [
    "This notebook estimates the number of V100 GPU-days used to train our adversaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3218493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import pprint\n",
    "import re\n",
    "from typing import Dict, Mapping, Optional, Union\n",
    "\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "\n",
    "HOURS_TO_SECONDS = 60 * 60\n",
    "DAYS_TO_SECONDS = 24 * 60 * 60\n",
    "# Estimate of how many V100 GPU-days is 1 A6000 GPU-day using this data:\n",
    "# https://www.notion.so/chaiberkeley/Benchmark-KataGo-victimplay-on-different-hardware-295ac2d430404430b8a1e0232f72b240\n",
    "# - On cp505, 3 A6000 victimplay workers generated 250k rows in 9h30m and 7\n",
    "#   V100 workers generated 250k rows in 6h44m. This corresponds to an A6000 worker\n",
    "#   being 1.6538x faster.\n",
    "# - On cp127, 3 A6000 workers generated 1002027 rows in 16h03 and 7 V100 workers\n",
    "#   generated 1019074 rows in 12h16. This corresponds to an A6000 worker being\n",
    "#   1.7535x faster.\n",
    "# - The mean of 1.6537 and 1.7535 is 1.7036.\n",
    "#\n",
    "# Comparison:\n",
    "# - At https://lambdalabs.com/gpu-benchmarks with fp16 precision,\n",
    "#   Lambda measures the conversion factor to be 1.48.\n",
    "A6000_TO_V100_GPU_DAY = 1.703643"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0680a",
   "metadata": {},
   "source": [
    "## Conversions to A6000 GPU-days\n",
    "\n",
    "Our adversaries were trained using A6000, A4000, A100 40GB,\n",
    "and A100 80GB GPUs. We'll estimate how many A6000 GPU-days is\n",
    "1 GPU-day on each of these GPU types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8629d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_victimplay_log_line_timestamp(line: str) -> Optional[datetime.datetime]:\n",
    "    \"\"\"Fetches the timestamp from a line in a victimplay log file.\"\"\"\n",
    "    match = re.match(r\"([0-9 \\-+:]+): \", line)\n",
    "    if match is None:\n",
    "        return None\n",
    "    return dateutil.parser.parse(match.group(1))\n",
    "\n",
    "\n",
    "def get_victimplay_duration(log_filename: str) -> Optional[float]:\n",
    "    \"\"\"Returns how long the victimplay worker was generating games.\n",
    "\n",
    "    Args:\n",
    "      log_filename: Filename of the victimplay worker's log file.\n",
    "\n",
    "    Returns:\n",
    "        How long the worker was generating games in seconds.\n",
    "        Returns None if the worker did not generate any games.\n",
    "    \"\"\"\n",
    "    GAME_START_REGEX = re.compile(r\"starting game\")\n",
    "    TIMESTAMP_REGEX = re.compile(r\"([0-9 \\-+:]+): \")\n",
    "    with open(log_filename, \"r\") as f:\n",
    "        first_game_start_timestamp = None\n",
    "        for line in f:\n",
    "            if GAME_START_REGEX.search(line) is not None:\n",
    "                first_game_start_timestamp = get_victimplay_log_line_timestamp(line)\n",
    "                assert first_game_start_timestamp is not None\n",
    "                break\n",
    "        if first_game_start_timestamp is None:\n",
    "            return None\n",
    "\n",
    "        for line in f:\n",
    "            pass\n",
    "        last_line = line\n",
    "        last_timestamp = get_victimplay_log_line_timestamp(last_line)\n",
    "        assert last_timestamp is not None\n",
    "        return (last_timestamp - first_game_start_timestamp).total_seconds()\n",
    "\n",
    "\n",
    "def get_victimplay_games_finished(log_filename: str, game_limit=None) -> int:\n",
    "    \"\"\"Returns the number of games the victimplay worker completed.\n",
    "\n",
    "    Args:\n",
    "        log_filename: Filename of the victimplay worker's log file.\n",
    "        game_limit: If not None, then stop counting and return early if\n",
    "          this number of games is reached.\n",
    "    \"\"\"\n",
    "    GAME_FINISH_REGEX = re.compile(\"Game #\")\n",
    "    num_games_finished = 0\n",
    "    with open(log_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            if GAME_FINISH_REGEX.search(line) is not None:\n",
    "                num_games_finished += 1\n",
    "                if game_limit is not None and num_games_finished >= game_limit:\n",
    "                    break\n",
    "    return num_games_finished\n",
    "\n",
    "\n",
    "def get_victimplay_gpu_type(log_filename: str) -> Optional[str]:\n",
    "    \"\"\"Parses GPU type from victimplay log.\"\"\"\n",
    "    GPU_TYPE_REGEX = re.compile(r\"Found GPU (.*) memory\")\n",
    "    with open(log_filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            match = GPU_TYPE_REGEX.search(line)\n",
    "            if match is not None:\n",
    "                return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014f987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-SXM4-40GB throughput: Avg. 180.94829353581846 +- 7.091347343534531\n",
      "NVIDIA A100-SXM4-80GB throughput: Avg. 202.9935724100512 +- 1.4472585304743872\n",
      "NVIDIA RTX A4000 throughput: Avg. 67.93128417907852 +- 2.071138168948876\n",
      "NVIDIA RTX A6000 throughput: Avg. 108.38931872111866 +- 1.2438836439931913\n",
      "Conversions to A6000 GPU-days:\n",
      "{'NVIDIA A100-SXM4-40GB': 1.6694291990282837,\n",
      " 'NVIDIA A100-SXM4-80GB': 1.8728189715108872,\n",
      " 'NVIDIA RTX A4000': 0.6267341190128057,\n",
      " 'NVIDIA RTX A6000': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Victimplay runs on different GPU types with the same adversary+victim setup.\n",
    "# Experiment link: https://www.notion.so/chaiberkeley/adv-s300mil-v600-vs-cp505-v8-benchmarking-by-GPU-6b151352b64241d2a67c21b6fb1c8da6\n",
    "benchmarking_directories = [\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a100-40gb-20230203-163919\",\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a100-80gb-20230203-163757\",\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a4000-20230203-163607\",\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a6000-20230203-163319\",\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a100-40gb-20230206-131111\",\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a100-80gb-20230206-124106\",\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a4000-20230206-124105\",\n",
    "    \"/nas/ucb/k8/go-attack/victimplay/ttseng-bench-a6000-20230206-121545\",\n",
    "]\n",
    "\n",
    "# We'll count the number of games each victimplay worker completed\n",
    "# as a proxy for how performant the GPU type is for our workload.\n",
    "\n",
    "# Key = GPU type\n",
    "# Value = List of number of victimplay games per hour\n",
    "#        (1 entry for each victimplay worker)\n",
    "gpu_type_to_game_throughputs = collections.defaultdict(list)\n",
    "for directory in benchmarking_directories:\n",
    "    victimplay_logfiles = glob.glob(f\"{directory}/selfplay/log*.log\")\n",
    "    for logfile in victimplay_logfiles:\n",
    "        duration = get_victimplay_duration(logfile)\n",
    "        if duration is None:\n",
    "            continue\n",
    "        gpu_type = get_victimplay_gpu_type(logfile)\n",
    "        assert gpu_type is not None\n",
    "        games_finished = get_victimplay_games_finished(logfile)\n",
    "        throughput = games_finished / (duration / HOURS_TO_SECONDS)\n",
    "        gpu_type_to_game_throughputs[gpu_type].append(throughput)\n",
    "\n",
    "gpu_type_to_avg_throughput = {}\n",
    "for gpu_type, throughputs in gpu_type_to_game_throughputs.items():\n",
    "    avg = np.mean(throughputs)\n",
    "    stddev = np.std(throughputs)\n",
    "    print(f\"{gpu_type} throughput: Avg. {avg} +- {stddev}\")\n",
    "    gpu_type_to_avg_throughput[gpu_type] = avg\n",
    "\n",
    "a6000_throughput = gpu_type_to_avg_throughput[\"NVIDIA RTX A6000\"]\n",
    "# Key = GPU type\n",
    "# Value = Estimate of how many A6000 GPU-days is 1 GPU-day\n",
    "#         of this GPU type.\n",
    "gpu_type_to_a6000_gpu_days = {\n",
    "    gpu_type: throughput / a6000_throughput\n",
    "    for gpu_type, throughput in gpu_type_to_avg_throughput.items()\n",
    "}\n",
    "\n",
    "# Comparison points:\n",
    "# - https://www.notion.so/chaiberkeley/Benchmark-KataGo-victimplay-on-different-hardware-295ac2d430404430b8a1e0232f72b240\n",
    "#     1 A100 40GB GPU-day -> 1.2592 A6000 GPU-days\n",
    "#\n",
    "# - Eyeballing from the actual training victimplay logs in ttseng-avoid-pass-alive-coldstart-39-20221025-175949,\n",
    "#   I (tomtseng) got the following numbers:\n",
    "#     1 A4000 GPU-day     -> 0.6619 A6000 GPU-days\n",
    "#     1 A100 40GB GPU-day -> 1.3507 A6000 GPU-days\n",
    "#     1 A100 80GB GPU-day -> 1.5829 A6000 GPU-days\n",
    "# - At https://lambdalabs.com/gpu-benchmarks with fp16 precision, Lambda estimates\n",
    "#     1 A4000 GPU-day     -> 0.4275 A6000 GPU-days\n",
    "#     1 A100 40GB GPU-day -> 1.5541 A6000 GPU-days\n",
    "#     1 A100 80GB GPU-day -> 1.8378 A6000 GPU-days\n",
    "print(\"Conversions to A6000 GPU-days:\")\n",
    "pprint.pprint(gpu_type_to_a6000_gpu_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f7a2d",
   "metadata": {},
   "source": [
    "## V100 GPU-days used for training adversaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00b066f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modified_time(filename: Union[pathlib.Path, str]) -> datetime.datetime:\n",
    "    \"\"\"Returns the modified time of a file.\"\"\"\n",
    "    epoch_time = os.path.getmtime(filename)\n",
    "    return datetime.datetime.utcfromtimestamp(epoch_time)\n",
    "\n",
    "\n",
    "def get_adversary_written_time(\n",
    "    training_path: pathlib.Path,\n",
    "    adversary_name: str,\n",
    "):\n",
    "    \"\"\"Returns when the adversary model file was written.\"\"\"\n",
    "    adversary_file = training_path / \"models\" / adversary_name / \"model.bin.gz\"\n",
    "    return get_modified_time(adversary_file)\n",
    "\n",
    "\n",
    "def get_victimplay_gpu_days(\n",
    "    training_path: pathlib.Path,\n",
    "    adversary_name: str,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Returns the GPU-days used by the adversary's victimplay workers.\n",
    "\n",
    "    Args:\n",
    "        training_path: Output directory of the adversary's training run.\n",
    "        adversary_name: Name of the adversary.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping GPU type to how many GPU-seconds were used of\n",
    "        that GPU during victimplay.\n",
    "    \"\"\"\n",
    "    CREATION_TIME_REGEX = re.compile(r\"log(\\d{8}-\\d{6})-\")\n",
    "\n",
    "    gpu_type_to_seconds = collections.defaultdict(int)\n",
    "    adversary_written_time = get_adversary_written_time(training_path, adversary_name)\n",
    "    victimplay_logfiles = glob.glob(str(training_path / \"selfplay\" / \"log*.log\"))\n",
    "    for logfile in victimplay_logfiles:\n",
    "        finished_a_game = get_victimplay_games_finished(logfile, game_limit=1) > 0\n",
    "        if not finished_a_game:\n",
    "            # This victimplay worker didn't generate any data, so we'll just skip\n",
    "            # it. E.g., the cyclic-adversary had many workers crash early and not\n",
    "            # generate any data on Nov. 1 due to a bug.\n",
    "            continue\n",
    "\n",
    "        # Parse creation time (in UTC) from filename.\n",
    "        creation_time_match = CREATION_TIME_REGEX.search(logfile)\n",
    "        assert creation_time_match is not None\n",
    "        creation_time = dateutil.parser.parse(creation_time_match.group(1))\n",
    "        if creation_time > adversary_written_time:\n",
    "            continue\n",
    "\n",
    "        modified_time = min(get_modified_time(logfile), adversary_written_time)\n",
    "        time_alive_seconds = (modified_time - creation_time).total_seconds()\n",
    "        gpu_type = get_victimplay_gpu_type(logfile)\n",
    "        assert gpu_type is not None\n",
    "        gpu_type_to_seconds[gpu_type] += time_alive_seconds\n",
    "    return gpu_type_to_seconds\n",
    "\n",
    "\n",
    "def get_train_gpu_days(\n",
    "    training_path: pathlib.Path,\n",
    "    adversary_name: str,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Returns the GPU-days used by the adversary's train worker.\"\"\"\n",
    "    EPOCH_NUMBER_REGEX = re.compile(r\"BEGINNING NEXT EPOCH ([0-9]+)\")\n",
    "    TIMESTAMP_REGEX = re.compile(r\"Current time: ([0-9 \\-+:.]+)\")\n",
    "    GPU_REGEX = re.compile(r\"name: (.*) major:\")\n",
    "\n",
    "    gpu_type_to_seconds = collections.defaultdict(int)\n",
    "    adversary_written_time = get_adversary_written_time(training_path, adversary_name)\n",
    "    train_logfile = training_path / \"train\" / \"t0\" / \"stdout.txt\"\n",
    "    with open(train_logfile, \"r\") as f:\n",
    "        prev_epoch = 0\n",
    "        prev_timestamp = None\n",
    "        did_train_this_epoch = False\n",
    "        gpu_type = None\n",
    "        for l in f:\n",
    "            epoch_match = EPOCH_NUMBER_REGEX.match(l)\n",
    "            if epoch_match is not None:\n",
    "                epoch = int(epoch_match.group(1))\n",
    "                if epoch > prev_epoch:\n",
    "                    # The epoch number incremented, which means we trained\n",
    "                    # between prev_timestamp and the timestamp of this epoch\n",
    "                    # (which will appear in two more lines)\n",
    "                    did_train_this_epoch = True\n",
    "                prev_epoch = epoch\n",
    "\n",
    "            timestamp_match = TIMESTAMP_REGEX.match(l)\n",
    "            if timestamp_match is not None:\n",
    "                timestamp = dateutil.parser.parse(timestamp_match.group(1))\n",
    "                if did_train_this_epoch:\n",
    "                    assert gpu_type is not None\n",
    "                    gpu_type_to_seconds[gpu_type] += (\n",
    "                        min(timestamp, adversary_written_time) - prev_timestamp\n",
    "                    ).total_seconds()\n",
    "                    did_train_this_epoch = False\n",
    "                    gpu_type = False\n",
    "                if timestamp > adversary_written_time:\n",
    "                    break\n",
    "                prev_timestamp = timestamp\n",
    "\n",
    "            gpu_match = GPU_REGEX.match(l)\n",
    "            if gpu_match is not None:\n",
    "                gpu_type = gpu_match.group(1)\n",
    "    return gpu_type_to_seconds\n",
    "\n",
    "\n",
    "def get_v100_gpu_days(\n",
    "    training_path: pathlib.Path,\n",
    "    adversary_name: str,\n",
    "    verbose: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"Returns the estimated V100 GPU-days used to train the adversary.\n",
    "\n",
    "    Args:\n",
    "        training_path: Output directory of the adversary's training run.\n",
    "        adversary_name: Name of the adversary.\n",
    "        verbose: Whether to print out intermediate calculations.\n",
    "    \"\"\"\n",
    "    gpu_type_to_victimplay_seconds = get_victimplay_gpu_days(\n",
    "        training_path, adversary_name\n",
    "    )\n",
    "    gpu_type_to_train_seconds = get_train_gpu_days(training_path, adversary_name)\n",
    "    seconds_dicts = [\n",
    "        (\"victimplay\", gpu_type_to_victimplay_seconds),\n",
    "        (\"train\", gpu_type_to_train_seconds),\n",
    "    ]\n",
    "\n",
    "    total_v100_days = 0\n",
    "    for descriptor, seconds_dict in seconds_dicts:\n",
    "        if verbose:\n",
    "            days_dict = {\n",
    "                gpu_type: seconds / DAYS_TO_SECONDS\n",
    "                for gpu_type, seconds in seconds_dict.items()\n",
    "            }\n",
    "            print(f\"{descriptor} GPU usage:\")\n",
    "            pprint.pprint(days_dict)\n",
    "\n",
    "        for gpu_type, seconds in seconds_dict.items():\n",
    "            days = seconds / DAYS_TO_SECONDS\n",
    "            total_v100_days += (\n",
    "                days * gpu_type_to_a6000_gpu_days[gpu_type] * A6000_TO_V100_GPU_DAY\n",
    "            )\n",
    "    return total_v100_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cbeeae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victimplay GPU usage:\n",
      "{'NVIDIA RTX A6000': 1.7000779246759259}\n",
      "train GPU usage:\n",
      "{'NVIDIA RTX A6000': 0.10115825417824076}\n",
      "Pass-adversary V100 GPU days: 3.0686634074516492\n"
     ]
    }
   ],
   "source": [
    "v100_days = get_v100_gpu_days(\n",
    "    pathlib.Path(\"/nas/ucb/tony/go-attack/training/emcts1-curr/cp127-to-505-v1\"),\n",
    "    \"t0-s34090496-d8262123\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"Pass-adversary V100 GPU days:\", v100_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09d3948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victimplay GPU usage:\n",
      "{'NVIDIA A100-SXM4-40GB': 299.65091498769675,\n",
      " 'NVIDIA A100-SXM4-80GB': 222.4628226519676,\n",
      " 'NVIDIA RTX A4000': 61.84087257660878,\n",
      " 'NVIDIA RTX A6000': 347.5863040065741}\n",
      "train GPU usage:\n",
      "{'NVIDIA A100-SXM4-80GB': 0.4094241887731483,\n",
      " 'NVIDIA RTX A6000': 0.9957843217361119}\n",
      "Cyclic-adversary V100 GPU days: 2223.2289559821224\n"
     ]
    }
   ],
   "source": [
    "v100_days = get_v100_gpu_days(\n",
    "    pathlib.Path(\n",
    "        \"/nas/ucb/k8/go-attack/victimplay/ttseng-avoid-pass-alive-coldstart-39-20221025-175949\"\n",
    "    ),\n",
    "    \"t0-s545065216-d136760487\",\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"Cyclic-adversary V100 GPU days:\", v100_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe597ad",
   "metadata": {},
   "source": [
    "## Cyclic-adversary GPU-days vs. win rate\n",
    "\n",
    "We use a lot of GPU-days to train the cyclic-adversary, but perhaps it was already\n",
    "strong earlier in training. Let's plot GPU-days vs. adversary win rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
